{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains import SequentialChain\n",
    "from langchain.callbacks import get_openai_callback\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import traceback\n",
    "from dotenv import load_dotenv\n",
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mykey=os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=ChatOpenAI(openai_api_key=mykey,model_name=\"gpt-3.5-turbo\",temperature=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"C:/Users/anshu/OneDrive/Desktop/chaku/GenAI/GenAI/Response.json\",\"r\") as f:\n",
    "    RESPONSE_JSON=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'quiz': {'text': '{text}', 'subject': '{subject}', 'tone': '{tone}', 'questions': [{'question': 'Question 1 text based on the provided content', 'options': ['Option 1', 'Option 2', 'Option 3', 'Option 4'], 'correct_answer': 'Option 1'}, {'question': 'Question 2 text based on the provided content', 'options': ['Option 1', 'Option 2', 'Option 3', 'Option 4'], 'correct_answer': 'Option 2'}]}}\n"
     ]
    }
   ],
   "source": [
    "print(RESPONSE_JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE=\"\"\"\n",
    "TEXT:{text}\n",
    "You are an expert MCQ maker. Given the above text, it is your job to \\\n",
    "create a quiz of {number} multiple choice questions for {subject} students in {tone}.\\\n",
    "Make sure the questions are not repeated and check all the questions to conforming.\\\n",
    "Make sure to format your response like RESPONSE_JSON below and use it as a guide.\\\n",
    "Ensure to make {number} MCQs\n",
    "### RESPONSE_JSON\n",
    "{RESPONSE_JSON}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_generation_prompt=PromptTemplate(\n",
    "    input_variables=[\"text\",\"number\",\"subject\",\"tone\",\"RESPONSE_JSON\"],\n",
    "    template=TEMPLATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_chain=LLMChain(llm=llm,prompt=quiz_generation_prompt,output_key=\"quiz\",verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE2=\"\"\"\n",
    "You are an expert MCQ maker. Given the above text, it is your job to \\\n",
    "create a quiz of {subject} multiple choice questions to check for correct English usage. \\\n",
    "Make sure the questions are not repeated and check all the questions to ensure they conform to the standards. \\\n",
    "Make sure to format your response like RESPONSE_JSON below and use it as a guide. \\\n",
    "Ensure to make quiz MCQs:\n",
    "{quiz}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_evaluation_prompt=PromptTemplate(\n",
    "    input_variables=[\"subject\",\"quiz\"],\n",
    "    template=TEMPLATE2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_chain=LLMChain(llm=llm,prompt=quiz_generation_prompt,output_key=\"quiz\",verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
